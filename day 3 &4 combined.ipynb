<<<<<<< HEAD
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 1: Install Required Libraries\n",
        "!pip install --upgrade openai textstat tabulate\n",
        "\n",
        "# âœ… Step 2: Imports\n",
        "from openai import OpenAI\n",
        "import textstat\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# âœ… Step 3: Set up Groq Client\n",
        "client = OpenAI(\n",
        "    api_key=\"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\",  # Replace with your Groq API key\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# âœ… Step 4: Input Article\n",
        "research_article = \"\"\"\n",
        "Recent advancements in deep learning have significantly improved the accuracy of image classification tasks.\n",
        "This study focuses on implementing a convolutional neural network (CNN) model to classify medical images.\n",
        "The objective was to detect early signs of pneumonia from chest X-rays. The dataset used was NIH's chest X-ray dataset with over 100,000 images.\n",
        "The CNN architecture included multiple convolutional and pooling layers followed by fully connected layers.\n",
        "The model was trained using the Adam optimizer and binary cross-entropy loss function.\n",
        "Upon evaluation, the CNN model achieved an accuracy of 92.3% and a precision of 91.5%.\n",
        "The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis,\n",
        "potentially reducing the burden on radiologists.\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Step 5: Prompts\n",
        "\n",
        "# Zero-shot\n",
        "zero_shot_prompt = f\"\"\"\n",
        "Summarize the following research article in one paragraph (max 150 words), covering:\n",
        "background, research objective, method, results, and key takeaway.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\"\"\"\n",
        "\n",
        "# One-shot\n",
        "example_summary = \"\"\"\n",
        "This research explores how transformer models have revolutionized NLP. The study aimed to compare BERT and GPT on sentiment classification tasks. Using IMDB reviews as the dataset, the models were fine-tuned with the same hyperparameters. Results showed GPT outperformed BERT in both accuracy (89.5%) and inference speed. The findings suggest transformer-based generative models are more efficient for real-time NLP tasks.\n",
        "\"\"\"\n",
        "\n",
        "one_shot_prompt = f\"\"\"\n",
        "Summarize the following research article in one paragraph (max 150 words), covering:\n",
        "background, research objective, method, results, and key takeaway.\n",
        "\n",
        "Example:\n",
        "{example_summary}\n",
        "\n",
        "Now summarize:\n",
        "{research_article}\n",
        "\"\"\"\n",
        "\n",
        "# Few-shot\n",
        "few_shot_prompt = f\"\"\"\n",
        "Summarize the following research article in one paragraph (max 150 words), covering:\n",
        "background, research objective, method, results, and key takeaway.\n",
        "\n",
        "Example 1:\n",
        "This research explores how transformer models have revolutionized NLP. The study aimed to compare BERT and GPT on sentiment classification tasks. Using IMDB reviews as the dataset, the models were fine-tuned with the same hyperparameters. Results showed GPT outperformed BERT in both accuracy (89.5%) and inference speed. The findings suggest transformer-based generative models are more efficient for real-time NLP tasks.\n",
        "\n",
        "Example 2:\n",
        "This study investigates the use of Generative AI for customer service automation. Researchers fine-tuned an LLM on 100k customer support transcripts. The method included prompt tuning and reward modeling. The final model improved response accuracy by 28% and reduced human escalation by 35%. The key insight is that LLMs can significantly improve response quality and reduce operational costs.\n",
        "\n",
        "Now summarize:\n",
        "{research_article}\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Step 6: Generate Summary Function\n",
        "def generate_summary(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# âœ… Step 7: Evaluate Function\n",
        "def evaluate_summary(summary):\n",
        "    word_count = len(summary.split())\n",
        "    readability = textstat.flesch_reading_ease(summary)\n",
        "    keywords = ['background', 'objective', 'method', 'result', 'takeaway']\n",
        "    coverage_score = sum(1 for kw in keywords if kw in summary.lower())\n",
        "\n",
        "    total_score = (\n",
        "        (2 if word_count <= 150 else 0) +\n",
        "        (coverage_score / 5) * 5 +\n",
        "        (readability / 100) * 3\n",
        "    )\n",
        "    return {\n",
        "        \"word_count\": word_count,\n",
        "        \"coverage_score\": coverage_score,\n",
        "        \"readability\": round(readability, 2),\n",
        "        \"total_score\": round(total_score, 2)\n",
        "    }\n",
        "\n",
        "# âœ… Step 8: Run All Prompts\n",
        "prompts = {\n",
        "    \"Zero-shot\": zero_shot_prompt,\n",
        "    \"One-shot\": one_shot_prompt,\n",
        "    \"Few-shot\": few_shot_prompt\n",
        "}\n",
        "\n",
        "summaries = {}\n",
        "results = []\n",
        "for name, prompt in prompts.items():\n",
        "    summary = generate_summary(prompt)\n",
        "    summaries[name] = summary\n",
        "    eval_result = evaluate_summary(summary)\n",
        "    results.append([\n",
        "        name,\n",
        "        eval_result[\"word_count\"],\n",
        "        eval_result[\"coverage_score\"],\n",
        "        eval_result[\"readability\"],\n",
        "        eval_result[\"total_score\"]\n",
        "    ])\n",
        "\n",
        "    # âœ… Print the summary for each method\n",
        "    display(Markdown(f\"### âœï¸ {name} Summary:\\n\\n{summary}\"))\n",
        "\n",
        "# âœ… Step 9: Show Score Table\n",
        "headers = [\"Technique\", \"Word Count\", \"Coverage (out of 5)\", \"Readability\", \"Score (/10)\"]\n",
        "print(\"\\nğŸ“Š Prompting Evaluation Results:\")\n",
        "print(tabulate(results, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "# âœ… Step 10: Best Technique\n",
        "best = max(results, key=lambda x: x[-1])\n",
        "print(f\"\\nğŸ† Most Efficient Prompting Technique: **{best[0]}** with score {best[-1]}/10\")\n"
      ],
      "metadata": {
        "id": "m2HgWJiVNC5n",
        "outputId": "055d0b0f-9e38-4a87-839c-5b8187d3b299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.23.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### âœï¸ Zero-shot Summary:\n\nHere is a summary of the research article in one paragraph:\n\nBackground: Recent advancements in deep learning have improved image classification accuracy, leading to potential applications in medical image analysis. Research Objective: This study aimed to develop a convolutional neural network (CNN) model to detect early signs of pneumonia from chest X-rays. Method: The study used NIH's chest X-ray dataset with over 100,000 images and trained a CNN model with multiple convolutional and pooling layers, followed by fully connected layers, using the Adam optimizer and binary cross-entropy loss function. Results: The CNN model achieved an accuracy of 92.3% and a precision of 91.5%. Key Takeaway: The study demonstrates that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### âœï¸ One-shot Summary:\n\nHere is a summary of the research article in one paragraph:\n\nRecent advancements in deep learning have improved image classification tasks, and this study focuses on implementing a convolutional neural network (CNN) to classify medical images, specifically detecting early signs of pneumonia from chest X-rays. The objective was to develop an accurate model using the NIH's chest X-ray dataset with over 100,000 images. The CNN architecture was trained using the Adam optimizer and binary cross-entropy loss function. The results showed that the CNN model achieved an accuracy of 92.3% and a precision of 91.5%. The key takeaway is that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### âœï¸ Few-shot Summary:\n\nHere is a summary of the research article in one paragraph:\n\nRecent advancements in deep learning have improved image classification tasks, and this study implements a convolutional neural network (CNN) to classify medical images, specifically detecting early signs of pneumonia from chest X-rays. Using the NIH chest X-ray dataset with over 100,000 images, the CNN model was trained with the Adam optimizer and binary cross-entropy loss function. The results showed an accuracy of 92.3% and a precision of 91.5%. The key takeaway is that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Prompting Evaluation Results:\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ Technique   â”‚   Word Count â”‚   Coverage (out of 5) â”‚   Readability â”‚   Score (/10) â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ Zero-shot   â”‚          128 â”‚                     5 â”‚         19.29 â”‚          7.58 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ One-shot    â”‚          118 â”‚                     3 â”‚         24.84 â”‚          5.75 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Few-shot    â”‚          103 â”‚                     2 â”‚         27.4  â”‚          4.82 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "\n",
            "ğŸ† Most Efficient Prompting Technique: **Zero-shot** with score 7.58/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "from tabulate import tabulate\n",
        "import textstat\n",
        "from openai import OpenAI\n",
        "\n",
        "# âœ… Step 1: Install Required Libraries (if not already installed)\n",
        "!pip install -q openai textstat tabulate\n",
        "\n",
        "# âœ… Step 2: Set up Groq Client\n",
        "client = OpenAI(\n",
        "    api_key=\"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\",  # your Groq API key\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# âœ… Step 3: Define Research Article\n",
        "research_article = \"\"\"\n",
        "Recent advancements in deep learning have significantly improved the accuracy of image classification tasks.\n",
        "This study focuses on implementing a convolutional neural network (CNN) model to classify medical images.\n",
        "The objective was to detect early signs of pneumonia from chest X-rays. The dataset used was NIH's chest X-ray dataset with over 100,000 images.\n",
        "The CNN architecture included multiple convolutional and pooling layers followed by fully connected layers.\n",
        "The model was trained using the Adam optimizer and binary cross-entropy loss function.\n",
        "Upon evaluation, the CNN model achieved an accuracy of 92.3% and a precision of 91.5%.\n",
        "The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis,\n",
        "potentially reducing the burden on radiologists.\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Step 4: Prompt Variants\n",
        "advanced_prompts = {\n",
        "    \"Chain-of-Thought\": f\"\"\"\n",
        "Read the following article and think step by step. Identify the background, research objective, methodology, results, and key takeaway in that order. Then generate a single paragraph summary (max 150 words).\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Step-by-step reasoning and final summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"Tree-of-Thoughts\": f\"\"\"\n",
        "Break the article into logical branches â€” background, objective, method, results, conclusion. Think through each part and then summarize it in a single paragraph of up to 150 words.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Branch thoughts and final summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"Role-based\": f\"\"\"\n",
        "You are an expert science writer. Your task is to summarize this research article for an academic audience in a concise 150-word paragraph including intro, methods, results, and conclusion.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Expert summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"ReAct\": f\"\"\"\n",
        "Apply Reasoning + Action approach. First reason about the most relevant parts of the article. Then summarize it in a 150-word paragraph.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "[Reasoning]\n",
        "...\n",
        "\n",
        "[Action - Summary]:\n",
        "\"\"\",\n",
        "\n",
        "    \"Directional-Stimulus\": f\"\"\"\n",
        "Focus primarily on the method and results of this research article. Still include a brief background and takeaway in your 150-word summary.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Targeted summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"Step-Back\": f\"\"\"\n",
        "Take a step back and reflect on the overall contribution and message of the research. Summarize the article in a high-level overview (max 150 words).\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Reflective summary:\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# âœ… Step 5: Functions\n",
        "def generate_summary(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",  # Groq-supported LLM\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def evaluate_summary(summary):\n",
        "    word_count = len(summary.split())\n",
        "    readability = textstat.flesch_reading_ease(summary)\n",
        "    keywords = ['background', 'objective', 'method', 'result', 'takeaway']\n",
        "    coverage_score = sum(1 for kw in keywords if kw in summary.lower())\n",
        "\n",
        "    total_score = (\n",
        "        (2 if word_count <= 150 else 0) +       # Word limit: max 2 pts\n",
        "        (coverage_score / 5) * 5 +              # Coverage: max 5 pts\n",
        "        (readability / 100) * 3                 # Readability: max 3 pts\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"word_count\": word_count,\n",
        "        \"coverage_score\": coverage_score,\n",
        "        \"readability\": round(readability, 2),\n",
        "        \"total_score\": round(total_score, 2)\n",
        "    }\n",
        "\n",
        "# âœ… Step 6: Generate + Evaluate + Display Summaries\n",
        "advanced_summaries = {}\n",
        "advanced_results = {}\n",
        "\n",
        "headers = [\"Technique\", \"Word Count\", \"Coverage (/5)\", \"Readability\", \"Score (/10)\"]\n",
        "advanced_table = []\n",
        "\n",
        "for technique, prompt in advanced_prompts.items():\n",
        "    print(f\"\\nğŸ§  Generating summary using {technique} prompting...\")\n",
        "    summary = generate_summary(prompt)\n",
        "    result = evaluate_summary(summary)\n",
        "\n",
        "    advanced_summaries[technique] = summary\n",
        "    advanced_results[technique] = result\n",
        "    advanced_table.append([\n",
        "        technique,\n",
        "        result[\"word_count\"],\n",
        "        result[\"coverage_score\"],\n",
        "        result[\"readability\"],\n",
        "        result[\"total_score\"]\n",
        "    ])\n",
        "\n",
        "    display(Markdown(f\"### ğŸ”¹ {technique} Summary:\\n\\n{summary}\"))\n",
        "\n",
        "# âœ… Step 7: Show Table of Evaluation Scores\n",
        "print(\"\\nğŸ“Š Summary Evaluation Table:\")\n",
        "print(tabulate(advanced_table, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "# âœ… Step 8: Show Best Performing Prompt\n",
        "best_technique = max(advanced_results.items(), key=lambda x: x[1]['total_score'])\n",
        "print(f\"\\nğŸ† Best Technique: **{best_technique[0]}** with a score of {best_technique[1]['total_score']} / 10\")\n"
      ],
      "metadata": {
        "id": "E37xsq-2K38L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e889a82-3ff0-45b6-ae76-28a1e1c5006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Chain-of-Thought prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Chain-of-Thought Summary:\n\nHere is the step-by-step breakdown and summary:\n\n**Background**: Recent advancements in deep learning have improved image classification tasks, and this study applies this technology to medical image classification.\n\n**Research Objective**: The objective is to detect early signs of pneumonia from chest X-rays using a convolutional neural network (CNN) model.\n\n**Methodology**: The study uses the NIH's chest X-ray dataset with over 100,000 images and implements a CNN architecture with multiple convolutional and pooling layers followed by fully connected layers. The model is trained using the Adam optimizer and binary cross-entropy loss function.\n\n**Results**: The CNN model achieves an accuracy of 92.3% and a precision of 91.5%.\n\n**Key Takeaway**: Deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists.\n\n**Summary**: This study demonstrates the effectiveness of a convolutional neural network (CNN) model in detecting early signs of pneumonia from chest X-rays, achieving an accuracy of 92.3% and precision of 91.5%. The results suggest that deep learning models can aid in accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Tree-of-Thoughts prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Tree-of-Thoughts Summary:\n\nHere are the logical branches and a summary of each:\n\n**Background**: Recent advancements in deep learning have significantly improved the accuracy of image classification tasks. This provides a foundation for exploring the application of deep learning in medical image classification.\n\n**Objective**: The objective of this study is to detect early signs of pneumonia from chest X-rays using a convolutional neural network (CNN) model.\n\n**Method**: The study uses the NIH's chest X-ray dataset with over 100,000 images and a CNN architecture consisting of multiple convolutional and pooling layers followed by fully connected layers. The model is trained using the Adam optimizer and binary cross-entropy loss function.\n\n**Results**: The CNN model achieves an accuracy of 92.3% and a precision of 91.5% upon evaluation.\n\n**Conclusion**: The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists.\n\n**Final Summary (150 words)**:\nThis study explores the application of deep learning in medical image classification, specifically detecting early signs of pneumonia from chest X-rays. Using a convolutional neural network (CNN) model and the NIH's chest X-ray dataset, the study aims to improve medical diagnosis accuracy. The CNN architecture consists of multiple convolutional and pooling layers followed by fully connected layers, trained using the Adam optimizer and binary cross-entropy loss function. The model achieves an accuracy of 92.3% and a precision of 91.5%, indicating that deep learning models"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Role-based prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Role-based Summary:\n\nHere is a 150-word summary of the research article:\n\nRecent advances in deep learning have revolutionized image classification tasks, and this study leverages convolutional neural networks (CNNs) to detect early signs of pneumonia from chest X-rays. The researchers utilized the NIH chest X-ray dataset, comprising over 100,000 images, to train and evaluate their CNN model. The architecture consisted of multiple convolutional and pooling layers followed by fully connected layers, optimized using the Adam optimizer and binary cross-entropy loss function. The model achieved an accuracy of 92.3% and a precision of 91.5%, demonstrating its potential in assisting early and accurate medical diagnosis. These results suggest that deep learning models like CNNs can alleviate the burden on radiologists by providing a reliable diagnostic tool. The study's findings have significant implications for the development of AI-assisted diagnostic systems in medical imaging, paving the way for further research in this area."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using ReAct prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ ReAct Summary:\n\n[Reasoning]\n\nThe most relevant parts of the article are:\n\n* The use of a convolutional neural network (CNN) to classify medical images, specifically chest X-rays to detect early signs of pneumonia.\n* The large dataset used, consisting of over 100,000 images from NIH's chest X-ray dataset.\n* The high accuracy and precision achieved by the CNN model, with an accuracy of 92.3% and a precision of 91.5%.\n* The potential impact of deep learning models like CNN on medical diagnosis, potentially reducing the burden on radiologists.\n\n[Action - Summary]\n\nThis study demonstrates the effectiveness of convolutional neural networks (CNNs) in medical image classification, specifically in detecting early signs of pneumonia from chest X-rays. Using a large dataset of over 100,000 images, the CNN model achieved an impressive accuracy of 92.3% and precision of 91.5%. These results suggest that deep learning models like CNN can significantly assist in early and accurate medical diagnosis, potentially reducing the workload of radiologists and improving patient outcomes. The study's findings have important implications for the use of AI in medical imaging and diagnosis."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Directional-Stimulus prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Directional-Stimulus Summary:\n\nHere is a 150-word summary of the research article:\n\n**Background**: Deep learning has significantly improved image classification tasks, and this study applies a convolutional neural network (CNN) to classify medical images for early detection of pneumonia from chest X-rays.\n\n**Method**: The study used NIH's chest X-ray dataset with over 100,000 images and a CNN architecture consisting of multiple convolutional and pooling layers followed by fully connected layers. The model was trained using the Adam optimizer and binary cross-entropy loss function.\n\n**Results**: The CNN model achieved an accuracy of 92.3% and a precision of 91.5% upon evaluation.\n\n**Takeaway**: The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists. This study demonstrates the potential of CNNs in medical image classification, highlighting their potential to improve healthcare outcomes."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Step-Back prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Step-Back Summary:\n\nHere is a high-level overview of the article in 150 words:\n\nThis study leverages deep learning to develop a convolutional neural network (CNN) model for classifying medical images, specifically detecting early signs of pneumonia from chest X-rays. Using a large dataset of over 100,000 images, the model achieved an impressive accuracy of 92.3% and precision of 91.5%. The results demonstrate the potential of deep learning models like CNNs to support early and accurate medical diagnosis, which could significantly reduce the workload of radiologists. This research contributes to the advancement of medical image analysis, highlighting the capabilities of AI in improving healthcare outcomes. By harnessing the power of deep learning, this study paves the way for further exploration of AI-assisted medical diagnosis, ultimately enhancing patient care and outcomes."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Summary Evaluation Table:\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ Technique            â”‚   Word Count â”‚   Coverage (/5) â”‚   Readability â”‚   Score (/10) â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ Chain-of-Thought     â”‚          176 â”‚               5 â”‚         21.21 â”‚          5.64 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Tree-of-Thoughts     â”‚          233 â”‚               4 â”‚         24.05 â”‚          4.72 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Role-based           â”‚          147 â”‚               1 â”‚         20.14 â”‚          3.6  â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ReAct                â”‚          178 â”‚               1 â”‚         23.01 â”‚          1.69 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Directional-Stimulus â”‚          138 â”‚               4 â”‚         19.51 â”‚          6.59 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Step-Back            â”‚          127 â”‚               1 â”‚         20.81 â”‚          3.62 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "\n",
            "ğŸ† Best Technique: **Directional-Stimulus** with a score of 6.59 / 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggYb_PuRLZR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
=======
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 1: Install Required Libraries\n",
        "!pip install --upgrade openai textstat tabulate\n",
        "\n",
        "# âœ… Step 2: Imports\n",
        "from openai import OpenAI\n",
        "import textstat\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# âœ… Step 3: Set up Groq Client\n",
        "client = OpenAI(\n",
        "    api_key=\"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\",  # Replace with your Groq API key\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# âœ… Step 4: Input Article\n",
        "research_article = \"\"\"\n",
        "Recent advancements in deep learning have significantly improved the accuracy of image classification tasks.\n",
        "This study focuses on implementing a convolutional neural network (CNN) model to classify medical images.\n",
        "The objective was to detect early signs of pneumonia from chest X-rays. The dataset used was NIH's chest X-ray dataset with over 100,000 images.\n",
        "The CNN architecture included multiple convolutional and pooling layers followed by fully connected layers.\n",
        "The model was trained using the Adam optimizer and binary cross-entropy loss function.\n",
        "Upon evaluation, the CNN model achieved an accuracy of 92.3% and a precision of 91.5%.\n",
        "The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis,\n",
        "potentially reducing the burden on radiologists.\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Step 5: Prompts\n",
        "\n",
        "# Zero-shot\n",
        "zero_shot_prompt = f\"\"\"\n",
        "Summarize the following research article in one paragraph (max 150 words), covering:\n",
        "background, research objective, method, results, and key takeaway.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\"\"\"\n",
        "\n",
        "# One-shot\n",
        "example_summary = \"\"\"\n",
        "This research explores how transformer models have revolutionized NLP. The study aimed to compare BERT and GPT on sentiment classification tasks. Using IMDB reviews as the dataset, the models were fine-tuned with the same hyperparameters. Results showed GPT outperformed BERT in both accuracy (89.5%) and inference speed. The findings suggest transformer-based generative models are more efficient for real-time NLP tasks.\n",
        "\"\"\"\n",
        "\n",
        "one_shot_prompt = f\"\"\"\n",
        "Summarize the following research article in one paragraph (max 150 words), covering:\n",
        "background, research objective, method, results, and key takeaway.\n",
        "\n",
        "Example:\n",
        "{example_summary}\n",
        "\n",
        "Now summarize:\n",
        "{research_article}\n",
        "\"\"\"\n",
        "\n",
        "# Few-shot\n",
        "few_shot_prompt = f\"\"\"\n",
        "Summarize the following research article in one paragraph (max 150 words), covering:\n",
        "background, research objective, method, results, and key takeaway.\n",
        "\n",
        "Example 1:\n",
        "This research explores how transformer models have revolutionized NLP. The study aimed to compare BERT and GPT on sentiment classification tasks. Using IMDB reviews as the dataset, the models were fine-tuned with the same hyperparameters. Results showed GPT outperformed BERT in both accuracy (89.5%) and inference speed. The findings suggest transformer-based generative models are more efficient for real-time NLP tasks.\n",
        "\n",
        "Example 2:\n",
        "This study investigates the use of Generative AI for customer service automation. Researchers fine-tuned an LLM on 100k customer support transcripts. The method included prompt tuning and reward modeling. The final model improved response accuracy by 28% and reduced human escalation by 35%. The key insight is that LLMs can significantly improve response quality and reduce operational costs.\n",
        "\n",
        "Now summarize:\n",
        "{research_article}\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Step 6: Generate Summary Function\n",
        "def generate_summary(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# âœ… Step 7: Evaluate Function\n",
        "def evaluate_summary(summary):\n",
        "    word_count = len(summary.split())\n",
        "    readability = textstat.flesch_reading_ease(summary)\n",
        "    keywords = ['background', 'objective', 'method', 'result', 'takeaway']\n",
        "    coverage_score = sum(1 for kw in keywords if kw in summary.lower())\n",
        "\n",
        "    total_score = (\n",
        "        (2 if word_count <= 150 else 0) +\n",
        "        (coverage_score / 5) * 5 +\n",
        "        (readability / 100) * 3\n",
        "    )\n",
        "    return {\n",
        "        \"word_count\": word_count,\n",
        "        \"coverage_score\": coverage_score,\n",
        "        \"readability\": round(readability, 2),\n",
        "        \"total_score\": round(total_score, 2)\n",
        "    }\n",
        "\n",
        "# âœ… Step 8: Run All Prompts\n",
        "prompts = {\n",
        "    \"Zero-shot\": zero_shot_prompt,\n",
        "    \"One-shot\": one_shot_prompt,\n",
        "    \"Few-shot\": few_shot_prompt\n",
        "}\n",
        "\n",
        "summaries = {}\n",
        "results = []\n",
        "for name, prompt in prompts.items():\n",
        "    summary = generate_summary(prompt)\n",
        "    summaries[name] = summary\n",
        "    eval_result = evaluate_summary(summary)\n",
        "    results.append([\n",
        "        name,\n",
        "        eval_result[\"word_count\"],\n",
        "        eval_result[\"coverage_score\"],\n",
        "        eval_result[\"readability\"],\n",
        "        eval_result[\"total_score\"]\n",
        "    ])\n",
        "\n",
        "    # âœ… Print the summary for each method\n",
        "    display(Markdown(f\"### âœï¸ {name} Summary:\\n\\n{summary}\"))\n",
        "\n",
        "# âœ… Step 9: Show Score Table\n",
        "headers = [\"Technique\", \"Word Count\", \"Coverage (out of 5)\", \"Readability\", \"Score (/10)\"]\n",
        "print(\"\\nğŸ“Š Prompting Evaluation Results:\")\n",
        "print(tabulate(results, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "# âœ… Step 10: Best Technique\n",
        "best = max(results, key=lambda x: x[-1])\n",
        "print(f\"\\nğŸ† Most Efficient Prompting Technique: **{best[0]}** with score {best[-1]}/10\")\n"
      ],
      "metadata": {
        "id": "m2HgWJiVNC5n",
        "outputId": "055d0b0f-9e38-4a87-839c-5b8187d3b299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.23.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### âœï¸ Zero-shot Summary:\n\nHere is a summary of the research article in one paragraph:\n\nBackground: Recent advancements in deep learning have improved image classification accuracy, leading to potential applications in medical image analysis. Research Objective: This study aimed to develop a convolutional neural network (CNN) model to detect early signs of pneumonia from chest X-rays. Method: The study used NIH's chest X-ray dataset with over 100,000 images and trained a CNN model with multiple convolutional and pooling layers, followed by fully connected layers, using the Adam optimizer and binary cross-entropy loss function. Results: The CNN model achieved an accuracy of 92.3% and a precision of 91.5%. Key Takeaway: The study demonstrates that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### âœï¸ One-shot Summary:\n\nHere is a summary of the research article in one paragraph:\n\nRecent advancements in deep learning have improved image classification tasks, and this study focuses on implementing a convolutional neural network (CNN) to classify medical images, specifically detecting early signs of pneumonia from chest X-rays. The objective was to develop an accurate model using the NIH's chest X-ray dataset with over 100,000 images. The CNN architecture was trained using the Adam optimizer and binary cross-entropy loss function. The results showed that the CNN model achieved an accuracy of 92.3% and a precision of 91.5%. The key takeaway is that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### âœï¸ Few-shot Summary:\n\nHere is a summary of the research article in one paragraph:\n\nRecent advancements in deep learning have improved image classification tasks, and this study implements a convolutional neural network (CNN) to classify medical images, specifically detecting early signs of pneumonia from chest X-rays. Using the NIH chest X-ray dataset with over 100,000 images, the CNN model was trained with the Adam optimizer and binary cross-entropy loss function. The results showed an accuracy of 92.3% and a precision of 91.5%. The key takeaway is that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Prompting Evaluation Results:\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ Technique   â”‚   Word Count â”‚   Coverage (out of 5) â”‚   Readability â”‚   Score (/10) â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ Zero-shot   â”‚          128 â”‚                     5 â”‚         19.29 â”‚          7.58 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ One-shot    â”‚          118 â”‚                     3 â”‚         24.84 â”‚          5.75 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Few-shot    â”‚          103 â”‚                     2 â”‚         27.4  â”‚          4.82 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "\n",
            "ğŸ† Most Efficient Prompting Technique: **Zero-shot** with score 7.58/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "from tabulate import tabulate\n",
        "import textstat\n",
        "from openai import OpenAI\n",
        "\n",
        "# âœ… Step 1: Install Required Libraries (if not already installed)\n",
        "!pip install -q openai textstat tabulate\n",
        "\n",
        "# âœ… Step 2: Set up Groq Client\n",
        "client = OpenAI(\n",
        "    api_key=\"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\",  # your Groq API key\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# âœ… Step 3: Define Research Article\n",
        "research_article = \"\"\"\n",
        "Recent advancements in deep learning have significantly improved the accuracy of image classification tasks.\n",
        "This study focuses on implementing a convolutional neural network (CNN) model to classify medical images.\n",
        "The objective was to detect early signs of pneumonia from chest X-rays. The dataset used was NIH's chest X-ray dataset with over 100,000 images.\n",
        "The CNN architecture included multiple convolutional and pooling layers followed by fully connected layers.\n",
        "The model was trained using the Adam optimizer and binary cross-entropy loss function.\n",
        "Upon evaluation, the CNN model achieved an accuracy of 92.3% and a precision of 91.5%.\n",
        "The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis,\n",
        "potentially reducing the burden on radiologists.\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Step 4: Prompt Variants\n",
        "advanced_prompts = {\n",
        "    \"Chain-of-Thought\": f\"\"\"\n",
        "Read the following article and think step by step. Identify the background, research objective, methodology, results, and key takeaway in that order. Then generate a single paragraph summary (max 150 words).\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Step-by-step reasoning and final summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"Tree-of-Thoughts\": f\"\"\"\n",
        "Break the article into logical branches â€” background, objective, method, results, conclusion. Think through each part and then summarize it in a single paragraph of up to 150 words.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Branch thoughts and final summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"Role-based\": f\"\"\"\n",
        "You are an expert science writer. Your task is to summarize this research article for an academic audience in a concise 150-word paragraph including intro, methods, results, and conclusion.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Expert summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"ReAct\": f\"\"\"\n",
        "Apply Reasoning + Action approach. First reason about the most relevant parts of the article. Then summarize it in a 150-word paragraph.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "[Reasoning]\n",
        "...\n",
        "\n",
        "[Action - Summary]:\n",
        "\"\"\",\n",
        "\n",
        "    \"Directional-Stimulus\": f\"\"\"\n",
        "Focus primarily on the method and results of this research article. Still include a brief background and takeaway in your 150-word summary.\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Targeted summary:\n",
        "\"\"\",\n",
        "\n",
        "    \"Step-Back\": f\"\"\"\n",
        "Take a step back and reflect on the overall contribution and message of the research. Summarize the article in a high-level overview (max 150 words).\n",
        "\n",
        "Article:\n",
        "{research_article}\n",
        "\n",
        "Reflective summary:\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# âœ… Step 5: Functions\n",
        "def generate_summary(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",  # Groq-supported LLM\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def evaluate_summary(summary):\n",
        "    word_count = len(summary.split())\n",
        "    readability = textstat.flesch_reading_ease(summary)\n",
        "    keywords = ['background', 'objective', 'method', 'result', 'takeaway']\n",
        "    coverage_score = sum(1 for kw in keywords if kw in summary.lower())\n",
        "\n",
        "    total_score = (\n",
        "        (2 if word_count <= 150 else 0) +       # Word limit: max 2 pts\n",
        "        (coverage_score / 5) * 5 +              # Coverage: max 5 pts\n",
        "        (readability / 100) * 3                 # Readability: max 3 pts\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"word_count\": word_count,\n",
        "        \"coverage_score\": coverage_score,\n",
        "        \"readability\": round(readability, 2),\n",
        "        \"total_score\": round(total_score, 2)\n",
        "    }\n",
        "\n",
        "# âœ… Step 6: Generate + Evaluate + Display Summaries\n",
        "advanced_summaries = {}\n",
        "advanced_results = {}\n",
        "\n",
        "headers = [\"Technique\", \"Word Count\", \"Coverage (/5)\", \"Readability\", \"Score (/10)\"]\n",
        "advanced_table = []\n",
        "\n",
        "for technique, prompt in advanced_prompts.items():\n",
        "    print(f\"\\nğŸ§  Generating summary using {technique} prompting...\")\n",
        "    summary = generate_summary(prompt)\n",
        "    result = evaluate_summary(summary)\n",
        "\n",
        "    advanced_summaries[technique] = summary\n",
        "    advanced_results[technique] = result\n",
        "    advanced_table.append([\n",
        "        technique,\n",
        "        result[\"word_count\"],\n",
        "        result[\"coverage_score\"],\n",
        "        result[\"readability\"],\n",
        "        result[\"total_score\"]\n",
        "    ])\n",
        "\n",
        "    display(Markdown(f\"### ğŸ”¹ {technique} Summary:\\n\\n{summary}\"))\n",
        "\n",
        "# âœ… Step 7: Show Table of Evaluation Scores\n",
        "print(\"\\nğŸ“Š Summary Evaluation Table:\")\n",
        "print(tabulate(advanced_table, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "# âœ… Step 8: Show Best Performing Prompt\n",
        "best_technique = max(advanced_results.items(), key=lambda x: x[1]['total_score'])\n",
        "print(f\"\\nğŸ† Best Technique: **{best_technique[0]}** with a score of {best_technique[1]['total_score']} / 10\")\n"
      ],
      "metadata": {
        "id": "E37xsq-2K38L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e889a82-3ff0-45b6-ae76-28a1e1c5006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Chain-of-Thought prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Chain-of-Thought Summary:\n\nHere is the step-by-step breakdown and summary:\n\n**Background**: Recent advancements in deep learning have improved image classification tasks, and this study applies this technology to medical image classification.\n\n**Research Objective**: The objective is to detect early signs of pneumonia from chest X-rays using a convolutional neural network (CNN) model.\n\n**Methodology**: The study uses the NIH's chest X-ray dataset with over 100,000 images and implements a CNN architecture with multiple convolutional and pooling layers followed by fully connected layers. The model is trained using the Adam optimizer and binary cross-entropy loss function.\n\n**Results**: The CNN model achieves an accuracy of 92.3% and a precision of 91.5%.\n\n**Key Takeaway**: Deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists.\n\n**Summary**: This study demonstrates the effectiveness of a convolutional neural network (CNN) model in detecting early signs of pneumonia from chest X-rays, achieving an accuracy of 92.3% and precision of 91.5%. The results suggest that deep learning models can aid in accurate medical diagnosis, potentially reducing the burden on radiologists."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Tree-of-Thoughts prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Tree-of-Thoughts Summary:\n\nHere are the logical branches and a summary of each:\n\n**Background**: Recent advancements in deep learning have significantly improved the accuracy of image classification tasks. This provides a foundation for exploring the application of deep learning in medical image classification.\n\n**Objective**: The objective of this study is to detect early signs of pneumonia from chest X-rays using a convolutional neural network (CNN) model.\n\n**Method**: The study uses the NIH's chest X-ray dataset with over 100,000 images and a CNN architecture consisting of multiple convolutional and pooling layers followed by fully connected layers. The model is trained using the Adam optimizer and binary cross-entropy loss function.\n\n**Results**: The CNN model achieves an accuracy of 92.3% and a precision of 91.5% upon evaluation.\n\n**Conclusion**: The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists.\n\n**Final Summary (150 words)**:\nThis study explores the application of deep learning in medical image classification, specifically detecting early signs of pneumonia from chest X-rays. Using a convolutional neural network (CNN) model and the NIH's chest X-ray dataset, the study aims to improve medical diagnosis accuracy. The CNN architecture consists of multiple convolutional and pooling layers followed by fully connected layers, trained using the Adam optimizer and binary cross-entropy loss function. The model achieves an accuracy of 92.3% and a precision of 91.5%, indicating that deep learning models"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Role-based prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Role-based Summary:\n\nHere is a 150-word summary of the research article:\n\nRecent advances in deep learning have revolutionized image classification tasks, and this study leverages convolutional neural networks (CNNs) to detect early signs of pneumonia from chest X-rays. The researchers utilized the NIH chest X-ray dataset, comprising over 100,000 images, to train and evaluate their CNN model. The architecture consisted of multiple convolutional and pooling layers followed by fully connected layers, optimized using the Adam optimizer and binary cross-entropy loss function. The model achieved an accuracy of 92.3% and a precision of 91.5%, demonstrating its potential in assisting early and accurate medical diagnosis. These results suggest that deep learning models like CNNs can alleviate the burden on radiologists by providing a reliable diagnostic tool. The study's findings have significant implications for the development of AI-assisted diagnostic systems in medical imaging, paving the way for further research in this area."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using ReAct prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ ReAct Summary:\n\n[Reasoning]\n\nThe most relevant parts of the article are:\n\n* The use of a convolutional neural network (CNN) to classify medical images, specifically chest X-rays to detect early signs of pneumonia.\n* The large dataset used, consisting of over 100,000 images from NIH's chest X-ray dataset.\n* The high accuracy and precision achieved by the CNN model, with an accuracy of 92.3% and a precision of 91.5%.\n* The potential impact of deep learning models like CNN on medical diagnosis, potentially reducing the burden on radiologists.\n\n[Action - Summary]\n\nThis study demonstrates the effectiveness of convolutional neural networks (CNNs) in medical image classification, specifically in detecting early signs of pneumonia from chest X-rays. Using a large dataset of over 100,000 images, the CNN model achieved an impressive accuracy of 92.3% and precision of 91.5%. These results suggest that deep learning models like CNN can significantly assist in early and accurate medical diagnosis, potentially reducing the workload of radiologists and improving patient outcomes. The study's findings have important implications for the use of AI in medical imaging and diagnosis."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Directional-Stimulus prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Directional-Stimulus Summary:\n\nHere is a 150-word summary of the research article:\n\n**Background**: Deep learning has significantly improved image classification tasks, and this study applies a convolutional neural network (CNN) to classify medical images for early detection of pneumonia from chest X-rays.\n\n**Method**: The study used NIH's chest X-ray dataset with over 100,000 images and a CNN architecture consisting of multiple convolutional and pooling layers followed by fully connected layers. The model was trained using the Adam optimizer and binary cross-entropy loss function.\n\n**Results**: The CNN model achieved an accuracy of 92.3% and a precision of 91.5% upon evaluation.\n\n**Takeaway**: The results indicate that deep learning models like CNN can assist in early and accurate medical diagnosis, potentially reducing the burden on radiologists. This study demonstrates the potential of CNNs in medical image classification, highlighting their potential to improve healthcare outcomes."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Generating summary using Step-Back prompting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ğŸ”¹ Step-Back Summary:\n\nHere is a high-level overview of the article in 150 words:\n\nThis study leverages deep learning to develop a convolutional neural network (CNN) model for classifying medical images, specifically detecting early signs of pneumonia from chest X-rays. Using a large dataset of over 100,000 images, the model achieved an impressive accuracy of 92.3% and precision of 91.5%. The results demonstrate the potential of deep learning models like CNNs to support early and accurate medical diagnosis, which could significantly reduce the workload of radiologists. This research contributes to the advancement of medical image analysis, highlighting the capabilities of AI in improving healthcare outcomes. By harnessing the power of deep learning, this study paves the way for further exploration of AI-assisted medical diagnosis, ultimately enhancing patient care and outcomes."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Summary Evaluation Table:\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ Technique            â”‚   Word Count â”‚   Coverage (/5) â”‚   Readability â”‚   Score (/10) â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ Chain-of-Thought     â”‚          176 â”‚               5 â”‚         21.21 â”‚          5.64 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Tree-of-Thoughts     â”‚          233 â”‚               4 â”‚         24.05 â”‚          4.72 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Role-based           â”‚          147 â”‚               1 â”‚         20.14 â”‚          3.6  â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ReAct                â”‚          178 â”‚               1 â”‚         23.01 â”‚          1.69 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Directional-Stimulus â”‚          138 â”‚               4 â”‚         19.51 â”‚          6.59 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Step-Back            â”‚          127 â”‚               1 â”‚         20.81 â”‚          3.62 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "\n",
            "ğŸ† Best Technique: **Directional-Stimulus** with a score of 6.59 / 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggYb_PuRLZR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
>>>>>>> d1a9f2ae22092ad0c5007c0eecb4f188ba6a5470
}